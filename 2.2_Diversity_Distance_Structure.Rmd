# Genetic Diversity {.imageChapter}

<div class="chapter_image"><img src="media/ch_milkweedbug.jpg"></div>

At a base level, genetic diversity is the fundamental components upon which evolution operates. Without diversity, there is no evolution and as such species cannot respond to selective pressure. Genetic diversity is a property of sampling locales.  It is created and maintained by demographic and evolutionary processes and the history of the organisms being examined.  It is also used as a surrogate measure for the consequences of several microevolutionary processes. In this section, we will examine how to estimate genetic diversity within a sample of individuals.

Estimates of within genetic diversity depend solely upon what you consider 'within a group.'  Often we use terms like Population, Deme, etc., but these have specific evolutionary and/or demographic meanings.  We are, however, largely ignorant if the samples we have collected are technically a part of a 'Population' in an evolutionary or at least practical random mating context.  As such, I will use the term population loosely, indicating that it is a collection of individuals sample from a geographic locale.  I am implicitly assuming a functional definition here (as I do in my research) that individuals sampled from the same 'Population' have a much higher probability of mating together than individuals sampled from different 'Populations.  This is 'Population Genetics' after all...

Here we will use the *Araptus attenuatus* co-dominant locus dataset that is included with the gstudio library.

```{r message=FALSE, warning=FALSE}
library(gstudio)
data(arapat)
```

Now the data is loaded into our session and we can extract the names of the loci (using `column_class()`, a convenience function returning the names of columns of a particular type). 

```{r}
locus_names <- column_class( arapat, "locus")
locus_names
```

Genetic diversity is estimated in R using the function `genetic_diversity()` contained within the gstudio library.  Here is the documentation for this function.  We will walk through the various parameters and illustrate their use with this dataset.

<div style="height:250px;white-space:pre-wrap;overflow:scroll;padding:8px;background:#eee;outline: 1px #eee;font-size:small"><pre>
genetic_diversity {gstudio} 						R Documentation

Estimate genetic diversity

Description

This function is the main one used for estimating genetic diversity among strata. Given the large number of genetic diversity metrics, not all potential types are included.

Usage
genetic_diversity(x, stratum = NULL, mode = c("A", "Ae", "A95", "He", "Ho",
  "Fis", "Pe")[2])

Arguments

x - A data.frame object with locus columns.
stratum - The strata by which the genetic distances are estimated. This can be an optional parameter when estimating distance measures calculated among individuals (default='Population').
mode - The particular genetic diversity metric that you are going to use. The gstudio package currently includes the following individual distance measures:
	A   	Number of alleles
	Ae	Effective number of alleles (default)
	A95	Number of alleles with frequency at least five percent
	He	Expected heterozygosity
	Ho	Observed heterozygosity
	Fis	Wright's Inbreeding coefficient (size corrected).
	Pe	Locus polymorphic index.

Value

A data.frame with columns for strata, diversity (mode), and potentially P(mode=0).

Author(s)

Rodney J. Dyer rjdyer@vcu.edu

Examples

AA <- locus( c("A","A") )
AB <- locus( c("A","B") )
BB <- locus( c("B","B") )
locus <- c(AA,AA,AA,AA,BB,BB,BB,AB,AB,AA)
locus2 <- c(AB,BB,AA,BB,BB,AB,AB,AA,AA,BB)
Population <- c(rep("Pop-A",5),rep("Pop-B",5))
df <- data.frame( Population, TPI=locus, PGM=locus2 )
genetic_diversity( df, mode="Ae")
</pre></div>


## Allelic Diversity

At the base level, a collection of alleles in a dataset provides an estimate of the breadth of genetic variation present. There are many measures commonly used in population genetics, though $A$, $A_{95}$, and $A_e$ are quite commonly encountered.  These terms are defined as:

*Frequency Independent Diversity* - The parameter $A$ measures the raw count of the number of alleles present in the sample.  This is a frequency independent estimate of diversity as it does not matter if the allele is only seen once or is seen hundreds of times in the sample.  

Technically, we define this parameter as  

\[
A = \ell
\]

where $\ell$ is the number of observed alleles.  We can estimate allelic diversity by passing the function either a vector of locus objects

```{r}
genetic_diversity( arapat$MP20, mode="A" )
```

or a `data.frame` that has one or more columns of data that are locus objects as determined by the `column_class()` function.  

```{r}
genetic_diversity( arapat, mode="A" )
```

The concern associated with using a parameter such as $A$ is that it throws away any information about relative abundance.  For example, a dataset with alleles found at an abundance of $N_A = 999$ and $N_B = 1$ would have the exact same frequency independent diversity as another sample with $N_A = N_B = 500$, namely $A = 2$.  

*Frequency Dependent Diversity* - A slightly more stringent approach may be to estimate the diversity of alleles in a frequency dependent fashion, specifying a particular cutoff.  The parameter $A_{95}$ is a common parameter that provides a count of the number of alleles present in a sample whose frequencies exceed a threshold of 5%.  

\[
A_{95} = \left| A_{freq(\ell)>0.05} \right|
\]

This threshold is entirely arbitrary in the same way that we use $\alpha=0.05$ as a cutoff in the teaching of formalized hypothesis testing.  It could just as easily be 3%, 1%, or 10% but has a historical trajectory  in its current form.  The $A_{95}$ parameter does remove some of the problems associated with rare alleles in our data sets as is shown by comparing the diversity of the most allele rich locus MP20 using $A$

```{r}
mp20.A <- genetic_diversity( arapat$MP20, mode="A")
mp20.A
```

and $A_{95}$

```{r}
mp20.A95 <- genetic_diversity( arapat$MP20, mode="A95")
mp20.A95
```

Here 15 of the alleles we observed in the full dataset occurred at a frequency less than 5%!

*Effective Number of Alleles* - Given the arbitrary nature of the cutoff for $A_{95}$, a more parsimonious approach may by one that measures the contribution of each allele to diversity in proportion to its frequency.  This is $A_e$ and it is defined as:

\[
A_e = \frac{1}{\sum_{i=1}^\ell p_i^2}
\]

and is the default mode of diversity provided by the `genetic_diversity()` function (e.g., the one you get if you do not specify `mode=`).

```{r}
genetic_diversity( arapat, mode="Ae")
```

Notice that $A \ge A_e \ge A_{95}$, as $A_e$ integrates the contributions of those low frequency alleles.  None of these parameters are perfect, though all provide some measurement of diversity at the level of the allele.

## Genotypic Diversity

In addition to diversity at the level of alleles, we also can estimate diversity at the level of the genotype.  There are several parameters that can be derived for genotypic diversity but the most common are observed and expected heterozygosity.  Observed heterozygosity is simply the fraction of all genotypes in the sample that are not homozygotes.

\[
H_O = \frac{N_{ij}}{N}
\]

where $N_{ij}$ is the count of all heterozygous genotypes.  The `mode="Ho"` option in `genetic_diversity()` returns these values. 

```{r}
genetic_diversity(arapat, mode="Ho")
```

The second parameter, expected heterozygosity ($H_e$), is slightly different in that it is a parameter that needs to be estimated from data.  It represents the fraction of genotypes in the dataset that are expected to be heterozygous, if the sample is in equilibrium.  The value for this function depends upon the data that you are estimating and how it is configured.  If it is estimated from a single locale, then the parameter can be estimated directly as the expected fraction that are not homozygous.

\[
H_E = 1 - \sum_{i=1}^\ell p_i^2
\]

(where $\ell$ is the number of alleles at the locus).  Here is an example of expected heterozygosity for the LTRS and MP20 loci.

```{r}
genetic_diversity( arapat$LTRS , mode="he")
genetic_diversity( arapat$MP20, mode="he" ) 
```

In an ideal world, we would be able to have enough resources to sample for these parameters with so many individuals, they would be well behaved.  Unfortunately, we do not live in the real world and in many cases our ability to sample lots of individuals is limited.  This problem is not a new thing, we estimate the sums of square and divide by $N-1$ instead of $N$ because if we we use the later, we are producing a biased estimate.  Unless you are working with *all* the samples, every time we make population genetic inferences we will be doing so on a subsample of the total data available.  The `arapat` data set is no where near a major component of the species, it is only a sample.  From this sample, we *estimate* allele frequencies on which we derive our *estimates* of parameters such as $H_E$.  As such, if we used the formulas above to estimate everything in every study, we would have biased estimators of... pretty much everything.  However, the fix is not one that is too difficult to put in, and it has a pretty well established set of behaviors.  As such, if we are estimating these parameters in a single locale (for more than one location, we have further corrections to make), we should probably apply a small sample size correction.  In general, this correction is:

\[
\hat{H}_e = \frac{2N}{2N-1}\left[ 1-\sum_{i=1}^\ell p_i^2 \right]
\]

The front part is a small sample size correction factor.  Its importance in your estimation diminishes as $N \to \infty$ as shown in Figure \@ref(fig:biasCorrection).  Once you get above $N=9$ individuals, there is an inflation of the estimated heterozygosity at a magnitude of less than 5%. 

```{r biasCorrection, echo=FALSE, fig.cap="Magnitude of the correction factor for small sample size estimations as a function of N.", message=FALSE}
require(ggplot2)
N <- 1:100
CF <- (2*N) / ( 2*N-1)
df <- data.frame( N, CF)
ggplot( df, aes(N,CF) ) + geom_line()
```



## Samples from Several Locales 

In addition to problems associated with estimating allele freqeuncies incorrectly (and requiring a sample size correction), when we estimate data from several locations, we also have a problem assocaited with the subset of locales relative to the total popualtion size, resulting in a furhter correction to account of the several biased samples you are taking.

\[
H_S = \frac{\tilde{N}}{\tilde{N}-1}\left[ 1 - \sum_{i=1}^\ell \frac{p_i^2}{K} - \frac{H_O}{2\tilde{N}} \right]
\]

where $\tilde{N}$ is the harmonic mean number of genotypes sampled across each of the $K$ strata.  Notice here I use the term $H_S$ instead of $H_E$ so that there isn't any doubt about the differences when we write and talk about these parameters.  This formulation (after Nei 1987) corrects for the sampling across separate  locations.  To indicate that your estimate is being made using subdivided groups of samples, pass the `stratum=` parameter to `genetic_diversity()` and set `mode="Hes".  We can see the magnitude of the correction by looking at a single population and comparing the estimates of $H_S$ for corrected and non-corrected parameters.

```{r}
pops <- arapat[ arapat$Population %in% c("32","101","102"),]
he <- genetic_diversity( pops, mode="He")
hes <- genetic_diversity(pops, stratum="Population", mode="Hes")[1:8,]
df <- data.frame(Locus=he[,1], He=he[,2], Hes=hes[,2])
df
```

```{r echo=FALSE}
df <- df[ !is.na(df$Hes),]
p <- format(round(cor(df$He,df$Hes),2),nsmall=3)
```


They are pretty close (Pearson's $\rho =$ `r p`), even when there are only `r nrow(pops)` individuals in the sample.^[The `NA` in the $H_{ES}$ parameter is because there are no smaples in one of the populations and a harmonic mean with a zero in it results in a divide-by-zero error.]  But they are off and this is a vitally important distinction because if you do not account for these differences you will percolate these errors up through your subsequent analyses (and this is a bad thing).

## Multilocus Diversity

There are several measures of individual locus diversity but few for multilocus diversity.  One potential measure for diversity across loci is to based upon the fraction of population that has unique multilocus genotypes.  This is defined as:

\[
D_m = \frac{N_{unique}}{N}
\]

and can be estimated using the function `mulitlocus_diversity()`.  Looking across the putative species indicated in the data set, we can see that in general, the Cape populations are much less diverse than those individuals samples throughout Baja California.

```{r}
multilocus_diversity( arapat[ arapat$Species=="Cape",])
multilocus_diversity( arapat[ arapat$Species=="Mainland",] )
multilocus_diversity( arapat[ arapat$Species=="Peninsula",] )
```

This is a pretty crude measurement but later when we examine models based upon conditional multilocus genetic distances, we need to make sure that the samples are both allelic rich and multilocus diverse and this approach is a nice way to do that.



## Rarefaction 

The primary reason for looking at diversity is to perform some comparison, which provides some insights into the biological and/or demographic processes influencing your data.  Without a basis for comparison, diversity estimates are just numbers. However, deriving an estimate of diversity is a statistical sampling process and as such we must be aware of the consequences our sampling regime has on the interpretation of the data.  This is where rarefaction comes in, a technique commonly used in ecology when comparing species richness among groups.

Here is an example of the problem sampling may interject into your analyses.   Consider a single locus with four alleles.

```{r message=FALSE, warning=FALSE}
library(gstudio)
data(arapat)
f <- data.frame( Allele=LETTERS[1:4], Frequency=0.25)
f
```

Selected as a random sample from an infinite population. The first sample has 5 individuals.

```{r}
pop1 <- make_population( f,N=5)
ae1 <- genetic_diversity( pop1, mode="Ae" )
ae1
```

And the second one has 100 individuals.

```{r}
pop2 <- make_population( f, N=100 )
ae2 <- genetic_diversity( pop2 )
ae2
```

The difference in estimated diversity among these groups are `abs( ae1 - ae2 ) = 0.15`.  Is this statistically different or are they the same?  Is it just because we sampled more individuals in the second set that we get higher values of $A_e$? Consider the `MP20` locus in the beetle data set, it has a total of 19 alleles present.  If we subsample this data and estimate the number of observed alleles, we see that there is an asymptotic relationship between sampling effort and estimates of allelic diversity.  Here is the code for estimating frequency independent diversity, $A$, using these data.

```{r}
loci <- arapat$MP20
sz <- c(2,5,10,15,20,50,100)
sample_sizes <- rep( sz, each=20 )
Ae <- rep(NA,length(sample_sizes))
for( i in 1:length(Ae)){
  loci <- sample( loci, size=length(loci), replace=FALSE)
  Ae[i] <- genetic_diversity( loci[1:sample_sizes[i]], mode="Ae" )$Ae
}
```

```{r echo=FALSE}
df <- data.frame( Sample_Size=factor(sample_sizes), Ae )
ggplot( df, aes(x=Sample_Size, y=Ae)) + geom_boxplot() + theme_bw() + xlab("Population Sample Size (N)") + ylab("Effective Allelic Diversity (Ae)")
```

The ‘curvy' nature of this relationship shows a few things.  

It takes a moderate sample size to capture the main set of alleles in the data set.  If we are looking at allocating sampling using only 5 individuals per locale, then we are not going to get the majority of the alleles present.

For the rare alleles, you really need to grab large at-site samples if estimates of diversity are the main component of what you are doing.  Do rare alleles aid in uncovering the biological processes you are interested in studying?  They may or may not.

For most purposes, we will use all the samples we have collected.  In many cases though, some locales may not have as many samples as other ones.  So, even with these data, if I have one locale with 10 samples and another with 50, how can I determine if the differences observed are due to true differences in the underlying diversity and which are from my sampling?  Just as in testing for HWE, we can use our new friend permutation to address the differences.

Rarefaction is the process of subsampling a larger dataset in smaller chunks such that we can estimate diversity among groups using the same number of individuals.  Here is an example in the beetle dataset where I am going to look at differences in diversity among samples ($N = 75$) collected in the cape regions of Baja California 

```{r}
ae.cape <- genetic_diversity( arapat[ arapat$Species=="Cape", "WNT"] )
ae.cape
```

and compare those to the genetic diversity observed from a smaller collection of individuals sampled from mainland Mexico ($N=36$).

```{r}
ae.mainland <- genetic_diversity( arapat[ arapat$Species=="Mainland", "WNT"] )$Ae
ae.mainland
```

The observed difference in effective allelic diversity, $A_{e,mainland} == A_{e,cape}$, could be because the Cape region of Baja California is more diverse or it could be because there are twice as many individuals in that sample.   

To perform a rarefaction on these data, we do the following:  

1. Use the size of the smallest population ($N$) as the sample size for all estimates.
Randomly sample individuals, without replacement, from the larger dataset in allocations of size $N$.  
2. Estimate diversity parameters on these subsamples and repeat to create a 'null distribution' of estimated diversity values.  
3. Compare your observed value in the smallest population to that distribution created by subsampling the larger population.  

From the data set, this is done by

```{r}
cape.pop <- arapat[ arapat$Species=="Cape","WNT"]
null.ae <- rarefaction( cape.pop, mode="Ae",size=36)
mean(null.ae)
```

So even if the samples sizes are the same, the mean level of diversity remains relatively constant.  The range in diversity

```{r}
range(null.ae)
```

is quite large.  Since this estimate is frequency based, random samples of alleles change the underlying estimate of Ae during each permutation.  

The observed estimate of diversity in the Mainland populations does fall within this range.  However, the null hypothesis states that $A_{e,mainland} = A_{e,cape}$ and if this is true, once we standardize sample size, we can take the distribution of permuted Ae values as a statement about what we should see if the null hypothesis were true.  As such, we can treat it probabilistically and estimate the probability that $A_e$, Mainland is drawn from this distribution.

```{r}
all.ae <- c( null.ae, ae.mainland)
P <- sum(ae.mainland <= null.ae) / ( length(all.ae) )
P
```

Or graphically, it can be depicted as below.

```{r echo=FALSE}
df <- data.frame( Observation = c(rep("Permuted",length(null.ae)),"Observed"),
                  Value = all.ae )
ggplot( df, aes(x=Value, fill=Observation)) + geom_histogram(bins=30) + theme_bw() + xlab("Allelic Diversity") + ylab("Frequency")
```


## Mapping Diversity

Estimating diversity is great and being able to compare two or more groups for their levels of diversity is even better.  But often we are looking for spatial patterns in our data.  Both R and gstudio provide easy interfaces for plotting data and later in the text we will see how to integrate raster and vector data into our workflows for more sublime approaches to characterizing population genetic processes.  In the mean time, it is amazingly easy to use basic plotting commands to get pretty informative output.  In this example, I extract the mean coordinate of each stratum in the arapat dataset and then estimate diversity at the level of these partitions and merge the diversity estimates for the AML locus into the coordinate data.frame.  

```{r}
library(gstudio)
data(arapat)
diversity <- genetic_diversity(arapat, stratum="Population", mode="Ae")
coords <- strata_coordinates(arapat)
coords <- merge( coords, diversity[ diversity$Locus == "AML", ] )
```

Then, I grab a map from the Google server and map my populations with diversity depicted as differences in the size of the points.  Note that the `ggmap()` function provides the base map that is retrieved but when we use `geom_point()` we need to specify the `aes()` and the `data=` part as these data are from the `data.frame` we made, not from the map we grabbed from Google.

```{r warning=FALSE}
library(ggmap)
map <- population_map(coords)
ggmap(map) + geom_point( aes(x=Longitude,y=Latitude,size=Ae), data=coords)
```



## Genetic Distance

One can measure the relative distance between items based upon some basic assumptions.  In Euclidean geometry, the underlying distance measures are based upon the triangle inequality.  The same kinds of approaches are available in characterizing genetic separation, either among individuals or among locales.  This chapter introduces some of the methodologies used in estimating genetic distances, how we analyze them, and how we portray our results in a graphical fashion amenable for interpretation.

Underlying most estimates of genetic distance are sets of geometric and/or evolutionary assumptions.  There are many different metrics that could be estimated from our genetic data, many of which will tell us the same general story.  However, there are specific features of our data that may make one kind of metric more appropriate than another type.

There are two main characteristics that control our ability to map collections of genotypes onto a real number line; Self identity and Symmetry.  Self identity implies that the distance, $\delta$, between an object (a single genotype or a collection of genotypes in a population) and itself must be zero: $\delta_{ii}=0$.  You are absolutely identical to yourself.  Symmetry implies that the distance between objects is independent of the order in which we measure it; $\delta_{ij} = \delta_{ji}$.  This can be a more problematic assumption in some cases and when we examine estimation of ecological distances later, we will see this may not be the case.  

If these two conditions are satisfied, the distance may be considered *metric* if (and only if) it satisfies the triangle inequality, $\delta_{ij} \le \delta_{ik} + \delta_{kj}$.  We've seen this relationship in Euclidean Geometry, the squared length of the hypotenuse is equal to the sum of the squared length of both legs in a triangle; $z^2 = x^2 + y^2$.

Genetic distance itself is not the final product that allows us to gain inferences about underlying population genetic processes.  Rather, it is the input into subsequent analyses.  This section focuses first on how we estimate distances, depending upon the level of interest, and then highlights some approaches for visualizing and gaining inferences from the distance matrix itself.  In later chapters, we return to the use of distance matrices when we examine network models and analyses based upon the idea of isolation models commonly used in modern population genetic analyses.

## Individual Genetic Distance

Genetic distance can be estimated based upon differences at many levels, the most basal of which is among individuals.  In the discussion of the individual genetic distances, the following genotypes will be used for illustrative purposes.

```{r message=FALSE}
require(gstudio)
AA <- locus(c("A", "A"))
AB <- locus(c("A", "B"))
BB <- locus(c("B", "B"))
BC <- locus(c("B", "C"))
AC <- locus(c("A", "C"))
CC <- locus(c("C", "C"))
Locus <- c(AA, AB, AC, BB, BC, CC)
Locus
```

### Euclidean Distance

The most basic distance metric we can use would be Euclidean.  Intuitively, we have a good idea about how this metric works as we use it every day.  Euclidean distance is estimated as:

\[
\delta_{eucl} = \sqrt{\sum_{i=1}^\ell (p_{xi}-p_{yi})^2}
\]

where $p_{x•}$ is a vector of allele frequencies measured on the $x^{th}$ individual. We can create these by translating the raw genotypes into multivariate data as we in the previous section on individual and population assignment.

```{r}
mv.genos <- to_mv(Locus)
mv.genos
```

and then using the `dist()` function that R has built-in to estimate $\delta_{eucl}$

```{r}
D.euc <- dist( mv.genos )
D.euc
```

The output variable, `D.euc`, is of type

```{r}
class(D.euc)
```

which is definitely not a matrix object. It is a specific data type that is used for dealing with distance matrices.  There are some analyses (variants of AMOVA and the Mantel test come to mind) that require the input matrix to be of type dist rather than of type matrix and don't do the conversion for you directly.

Because most distance matrices have a zero diagonal ($1^{st}$ requirement outlined previously) and symmetry (the upper diagonal is equal to the lower diagonal, the $2^{nd}$ requirement), it is possible to save computer memory by only dealing with the data below the diagonal.  Some analyses, such as an implementation of the Mantel test, require the use of dist objects instead of matrices.  

It is easy to convert between the two object types as necessary.

```{r}
D.euc <- as.matrix( D.euc )
D.euc
```

if you need to perform operations that are not available to dist objects (like matrix algebra).

### AMOVA Distance

Another geometric interpretation of inter-individual distance is that of Excoffier *et al.* (2004), dubbed AMOVA distance.  Smouse & Peakall (1999) provided the geometry of this relationship for diploid loci when discussing spatial autocorrelation.  AMOVA distance can be visualized as the distance between vertices and mid-points on an equilateral triangle.  Each segment is defined as having unit length and the distance is taken as the square of the distance between genotypes. 

```{r echo=FALSE}
knitr::include_graphics("media/AMOVA_Distance.png")
```

In R, we calculate it as:

```{r}
D.amova <- genetic_distance( Locus, mode="AMOVA" )
rownames(D.amova) <- colnames(D.amova) <- as.character( Locus )
D.amova
```

For completeness, the previous figure should be drawn as a tetrahedron with the possibility of four alleles at a locus (allowing for distances between two heterozygotes that do not share any alleles).  However, that is not an easy thing to draw for me...  The only interesting distance you'll need to think about (and perhaps grab a piece of paper and draw some triangles) is the distance between two two heterozygotes that share no alleles.  I'll leave it up to you to figure out that one (or use `genetic_distance()` for it).  

### Bray-Curtis Individual Distance

A distance metric that can be used to test differences among individuals or populations is that of Bray-Curtis.  This distance is a transformation of Jaccard's distance (see below) and is derived from an ecological ordination paper by Bray & Curtis (1957).

\[
D_C = 1 - 2\frac{\sum_{i=1}^\ell min(p_{X,i},p_{Y,i})}{\sum_{i=1}^\ell p_{X,i} + \sum_{i=1}^\ell p_{Y,i}}
\]

This parameter is bound by 0 on the lower end, indicating that the two items being compared are identical and 1 at the upper end indicating complete dissimilarity.  In R, this distance is defined in the vegan package for normal vegetation analysis and in gstudio for genetic data.  There is some confusion in the literature as to how this distance metric should be calculated and it is implied by Yoshioka (2008) that at least some of the implementations are actually Czekanowski distance.  At the time of this writing, there are some discrepancies between the distances that are calculated in different programs, whose names will be withdrawn to protect the innocent, so be aware.  In the end, it is not fealty to a particular distance metric that is important in our analyses, it is the ability of some metric to describe the variation we see.  

The implementation in gstudio uses allele counts across all loci.

### Ladder Distance

For microsatellite loci, which have a specific step-wise mutation model, a genetic distance metric can be created based upon the number of repeat motif differences at genotypes rather than just binary same/different alleles (as in the AMOVA distance before).  If the stepwise mutation process at microsatellite loci has played a significant role in shaping the structure on the landscape then we expect the kinds of spatial signal that is present in a ladder distance approach should differ from an approach that does not take into consideration the unique characteristics of this kind of locus.  If they say provide very similar kinds of inferences then it is more likely that mutation, as a process, has not shaped the history to a large extent.


## Population-Level Genetic Distances

If we are collecting data in such a way as to have pre-defined (or determined ex post facto) groups (populations or locales), several additional distance metrics can be derived.  Below are a few of the more common ones that you will run into.  It should be said that there is no dearth of genetic distance metrics available.

### Czekanowski (Manhattan) Distance

Perhaps the simplest distance metric is that of Czekanowski—more commonly referred to as Manhattan distance.  It is called Manhattan distance because it is a distance metric that is analagous to how you measure city-block distances.  It is relatively difficult in a city to walk from one place to another in a straight line, rather we are forced to walk down this street, turn walk down that one, etc.  

```{r echo=FALSE}
knitr::include_graphics("media/Chezkanowski_Distance.png")
```


Population allele frequencies can be plot on the linear axis $\sum_{i=1}^\ell p_i = 1$ and the distance between populations is the sum of the lengths separating each population on each of the $\ell$ axis.  This is calculated as:

\[
D_{Cz} = \frac{1}{2}\left| p_{i,x} - p_{i,y} \right|
\]

where the pipes, $|x|$, indicate taking the absolute value.  

### Rogers (Euclidean) Distance

Stepping up, slightly, in complexity, we get to Roger's distance.  This distance metric is roughly equivalent to Euclidean distance (and indeed in gstudio it is called euclidean).  

```{r echo=FALSE}
knitr::include_graphics("media/Rodgers_Distance.png")
```


Here we consider the allele frequencies as before but instead of taking the absolute values of the distances along each axis, we take the straight-line distance.   This is estimated as:

\[
D_R = \sqrt{ \frac{1}{2} \sum_{i=1}^\ell\left( p_{i,x} - p_{i,y}\right)^2 }
\]

This is a more common distance metric than that of Czkanowski and has been used in classification and taxonomy.  There are a few drawbacks to this distance metric that stem from not being based upon population genetic theory.  These may, or may not, be relevant to what you are doing with your data and where your data is from.  

1. This distance is not proportional to time of separation of populations.  There is no drift component to it.  
2. This distance is not proportional to the number of base-pair substitutions, which may be important if you are looking at haplotype divergence.  
3. This distance may loose sensitivity with increased allelic diversity.

If you are using this metric at short time intervals, have loci of moderately diversity, or are not concerned about homology, this is a quick metric.

### Nei's Genetic Distance

One of the most common distance metrics used is that of Nei, and is estimated as:

\[
I = \frac{\sum_{i=1}^L\sum_{j=1}^{\ell_{i}} p_{ij,x}p_{ij,y}}{\sqrt{\sum_{i=1}^L\left(\sum_{j=1}^{\ell_i} p_{ij,x}^2\right)\sum_{i=1}^L\left(\sum_{j=1}^{\ell_i} p_{ij,y}^2\right)}} 
\]

but more commonly referred to using the transform:

\[
D_{Nei} = -\ln(I)
\]

This metric is roughly linear in time, assuming a drift-mutation equilibrium.  Populations with longer periods of separation will have larger values of $D_{Nei}$.  If you think that drift and mutation are significant features that have shaped the divergence of your populations, then this is an appropriate metric to use.

### Conditional Genetic Distance

There is a final genetic distance that should be discussed here, Conditional Genetic Distance, derived from a network abstraction of genetic covariance by Dyer & Nason (2004).  However, both the rationale and the approach that produce these measures of distance rely on some approaches that need further development and will be put off until a more complete treatment can be done in the chapter on population graphs.



## Genetic Structure



The term 'structure' is used in many different ways in population genetics.  Essentially, data has genetic structure if there is a non-random association of genotypes across your sampling locations.  The interaction of population genetic processes create the genetic structure we see, though it is not easy to infer historical process from the presence of structure alone.  For this we need to rely upon more cleaver experimental design.  In this chapter we examine parameters designed to describe the amount of structure present in a dataset and how we can derive some level of inference from their magnitudes.

Structure in populations influences the distribution (spatial, ecological, and temporal) distribution of of alleles.  Until this point, we have focused on how alleles coalesce into genotypes at the individual level, local allele frequencies and the Hardy Weinberg expansion provide an expectation for the probability of seeing a heterozygote, for example.  As we scale up from the individual itself to the deme (or sub-population) in which it resides, we can also estimate heterozygosity.  As we coalesce these demes into populations, regions, continents, etc. we can also estimate expectations for heterozygosity at these levels as well. The deviance from these expectations at all levels can be captured in a statistic—the $F$-statistic we've seen already is on of them—useful for comparisons among studies, sites, etc. The $F$-statistics are perhaps the most misused parameters in population genetics but they have both a long history of use and pretty robust expectations with respect to how they will respond to various evolutionary processes.

In this section, we will explore genetic structure, *sensu lato*, providing examples of single and multilocus statistics and how we currently think they should be used.  

## Inbreeding 

Inbreeding is one of the most common deviations from random mating (and hence Hardy-Weinberg Equilibrium) that we encounter in natural populations.  Inbreeding is defined, sensu stricto, as mating between two related individuals.  This ranges from complete selfing, where one parent alone produces offspring, to consanguineous mating, where individuals with some degree of relatedness produce offspring.  The genetic consequences of inbreeding are entirely in how alleles are arranged into genotypes, not in changing allele frequencies.

The primary consequence of inbreeding is a reduction in the frequency of the heterozygous genotype.  Consider the following Punnet square where a heterozygote is producing a selfed offspring.

&nbsp; | $A$  | $B$
-----:|:----:|:----:
$A$   | $AA$ | $AB$
$B$   | $AB$ | $BB$

The offspring in the next generation are only 50% heterozygotes.  Each generation of selfing,  homozygotes produce homozygotes but only half of the offspring from heterozygotes stay as such. This process increases the relative frequency of homozygous genotypes in the population, though if you look at the offspring, the frequency of alleles do not change—there are as many A alleles as B alleles in the next generation of selfing. 

Conceptually, we can define an inbreeding parameter, $F$, depicting the extent to which genotype frequencies have deviated from HWE due to inbreeding.  But to do so, we need to differentiate between homozygote genotypes that have the same alleles because they are inbred (e.g., both alleles can be traced to a single allele in common ancestor) from those that are identical because they just happen to have the same allele (not of common ancestry). For this, we will define terms for these genotypes as:

**Autozygous** - Two alleles that are identical within a genotype because they came from the same individual in the previous generation. These alleles are Identical by Descent and will be found in the population at a rate of $pF$.

**Allozygous** - Two alleles that are identical within a genotype but they came from alternate individuals in the parental generation. These alleles have Identity by State and are expected to occur at a frequency of $p^2(1-F)$.

Together, the expected frequency of the AA genotype, $E[AA] = p^2(1-F) + pF$.

At the extremes, if there is no inbreeding—all homozygotes are allozygous—the inbreeding statistic, $F=0$ and the expectation reduces to $E[AA] = p^2$.  Conversely, if all offspring are the result of selfing, $F=1$ and $E[AA] = p$. 

Often the parameter $F$ is the subject of our analyses and the item that is to be estimated from genetic data.  Give the definition above, $F$ is defined as the proportional loss of heterozygosity and is estimated as:

\[
\begin{aligned}
F &= \frac{H_e - H_o}{H_e} \\ 
  &= 1 - \frac{H_o}{H_e}
\end{aligned}
\]

The key point here is that inbreeding (autozygosity) is estimated ‘relative' to the expected frequencies of non-inbred heterozygotes (allozygosity).

Selfing is the most extreme form of inbreeding is that of selfing—one parent donates both gametes to the offspring.  In selfing systems, the frequency of genotypes $P = freq(AA)$, $Q = freq(AB)$, and $R = freq(BB)$, change in through time in a predictable fashion providing us a quantitative approach to characterizing the duration of inbreeding from allele and genotype frequencies.  

From first principles, selfing for these genotypes produces the following expected offspring genotype frequencies:

Parent |	Offspring | Frequency
------:|:----------:|:----------
$AA$	 |    $AA$    |   	$P$
$AB$   |  $1/4\;AA$	|    $Q/4$
&nbsp; |	$1/2\;AB$ |    $Q/2$
&nbsp; |  $1/4\;BB$	|    $Q/4$
$BB$   |  $BB$      |	   $R$

Such that the genotype frequencies in the next generation are:

\[
\begin{aligned}
P_{t+1} &= P_t + \frac{1}{4}Q_t \\
Q_{t+1} &= \frac{1}{2}Q_t \\
R_{t+1} &= R_t + \frac{1}{4}R_t
\end{aligned}
\]

The interesting thing here is that the allele frequencies at the next generation are derived from the genotype frequencies as:

\[
p_{t+1} = P_{t+1} + \frac{1}{2}Q_{t+1}
\]

But with a little re-arrangement of terms, we see that 

\[
\begin{aligned}
p_{t+1} &= P_{t+1} + \frac{1}{2}Q_{t+1} \\
 &= \left(P_t + \frac{1}{4}Q_t \right) + \frac{1}{2}\left( \frac{1}{2}Q_t \right) \\
 &= P_t + \frac{1}{2}Q_t \\
 &= p_t
\end{aligned}
\]

showing that while genotype frequencies change with each generation of inbreeding, the underlying allele frequencies remain constant!  Inbreeding only changes how alleles are packed into genotypes and in not changing frequencies, does not result in evolutionary change, *sensu stricto*.


## Changes in F

For every generation with selfing, the average level of inbreeding in the population will increase.  The amount it increases depends upon how inbred the population already is, outbred populations will have larger $\delta F$ than similar populations with higher initial $F$.

### Theoretical Expectations

As expected, selfing changes the estimate of $F$ as well.  It changes across generations with continued selfing as:

\[
F_1 = 1 - \frac{H_O}{H_E} = 1 - \frac{Q_1}{2pq}
\]

for the first generation, 

\[
F_2 = 1 - \frac{ \frac{Q_1}{2} }{2pq}
\]

for the second, 

\[
F_3 = \frac{\frac{Q_2}{2}}{2pq}  = \frac{\frac{\frac{Q_1}{2}}{2}}{2pq}
\]

and the next

\[
F_4 = \frac{\frac{Q_3}{2}}{2pq}  = \frac{\frac{\frac{Q_2}{2}}{2}}{2pq} =
\frac{\frac{\frac{\frac{Q_1}{2}}{2}}{2}}{2pq}
\]

and so on.  Numerically, if $F_1=0$, then $F2 = 0.50, F3 = 0.75, and F4 = 0.875.  Each generation, $F$ approaches 1.0 by half way.  From this pattern, the change in $F$ each generation can be estimated as:

\[
F_{t+1} = \frac{1}{2} + \frac{1}{2}F_t
\]

for each generation or 

\[
F_t = 1 - \left(\frac{1}{2}\right)^t(1-F_O)
\]

for any arbitrary time, $t$, in the future given some starting level of inbreeding.  This expectation looks like:

```{r warning=FALSE, message=FALSE}
library(ggplot2)
T <- 0:15
F <- 1 - 0.5^T
df <- data.frame( T, F)
ggplot(df,aes(T,F)) + geom_line() + xlab("Generation (t)") + ylab("Inbreeding (F)")
```

## Simulation Example

These smooth expectations are nice but real data is a bit more complex.  Real data is not so clean but it is pretty easy to simulate this process and measure the change in inbreeding through time.  Here is how that can be done.

First, I'm going to start with a population in HWE with allele frequencies of $p=q$.  To do this, we start by importing the gstudio library and making raw genotypes.  We can replicate them to make a starting population with $N=100$ individuals.

```{r message=FALSE, warning=FALSE}
library(gstudio)
AA <- locus( c("A","A") )
AB <- locus( c("A","B") )
BB <- locus( c("B","B") )
pop <- data.frame(ID=1:100, Locus1=c( rep(AA,25), rep(AB,50), rep(BB,25) ) )
```


Just to check, we can see the starting allele frequencies as:

```{r}
frequencies(pop)
```

The inbreeding parameter, $F$, is estimated on a data.frame object that has at least one column of data of type locus using the wrapper function `genetic_diversity()` and passing it the `mode="Fis"` option—the 'is' subscript here is because there are additional $F$ statistics that may be calculated for different groups of individuals which will be covered in the section on genetic structure.  The parameter $F$ is estimated for each locus and the results are given in a data.frame.

```{r}
genetic_diversity(pop,mode="Fis")
```

I am going to simulate 10 replicate runs of selfing, each starting with this very population.  During each replicate, each individual will produce one and only one offspring through selfing using the function `mate()` and iterated across generations as in the expectation.  The parameter F will be recorded after all replications are finished plot against time.

```{r}
df$Category = "Expectations"
for( rep in 0:9 ) {
  data <- pop
  F <- rep(0, length(T) )
  for(t in T){
    # estimate F
    F[(t+1)] <- genetic_diversity(data,mode="Fis")$Fis[1]
    # self all adults to make offspring
    data <- mate( data, data, N=1 )
  }
  df.rep <- data.frame( T, F, Category=paste("Replicate",rep))
  df <- rbind( df, df.rep )
}
```

The variance around expectation is moderate shows that even if all expectations are met, real data is a bit messy—perhaps expectations are more of what you'd call ‘guidelines' than strict rules.

```{r echo=FALSE, fig.cap="Replicate simulations of inbreeding in purely selfing populations (colored lines) with theoretical expectation (black line)."}
ggplot() + geom_line(aes(T,F,color=Category),data=df[df$Category!="Expectations",]) + geom_point(aes(T,F,color=Category),data=df[df$Category!="Expectations",]) + geom_line(aes(T,F),data=df[df$Category=="Expectations",]) + geom_point(aes(T,F),data=df[df$Category=="Expectations",]) + xlab("Generation (t)") + ylab("Inbreeding (F)")
```


Not all species that can produce selfed offspring produce only selfed offspring.  In many systems, organisms may produce offspring that are a mix of inbred and outcross matings, a condition mixed mating systems.  Using the same approach, we can define expectations for allele frequencies (a cinch since they do not change), genotype frequencies (by mixing selfing and regular HWE expectations), and the evolution of the inbreeding parameter $F$.  

To quantify the effects of mixed mating systems, we need to define a new parameter, $s$, as the selfing rate.  This parameter determines the fraction of offspring due to selfing, with $s=0$ meaning all offspring are outcross, $s=1$ meaning they are all selfed, and intermediate values indicating a mix of both selfed and outcrossed offspring.

Given the selfing parameter, $s$, we can easily define the expectations for genotype frequencies at the next generation by adding the expectations for the purely selfed individuals ($s$) and the non-selfed individuals ($1-s$) as shown in the table below.

In the next generation, the expected frequency of $AA$ offspring would be:

\[
E[AA]_{t+1} = sP_t + s\frac{Q_t}{4} + (1-s)P_t^2 + (1-s)P_tQ_t + (1-s)\frac{Q_t^2}{4} 
\]

which simplifies down to:

\[
E[AA]_{t+1} = s\left[ P_t + \frac{Q_t}{4} \right] + (1-s)p_t^2
\]

In a similar fashion, the heterozygote is:

\[
E[AB]_{t+1} = s\frac{Q_t}{2} + (1-s)2p_tq_t
\]

and the other homozygote reduces to:
 
\[
E[BB]_{t+1} = s\left[ R_t + \frac{Q_t}{4} \right] + (1-s)q_t^2
\]

With these expectations, we can estimate the change in genotype frequencies through time for both allele and genotype frequencies. 

```{r}
p <- fAA <- fAB <- fBB <- rep(NA,10)
p[1] <- 0.25
fAA[1] <- p[1]^2
fAB[1] <- 2*p[1]*(1-p[1])
fBB[1] <- (1-p[1])^2
```

This produces the output of these frequency vectors as:


```{r}
cbind(p,fAA,fAB,fBB)
```

Then iterate through generations 2-10 (or as long as we need to go so that we can see the pattern) as:

```{r}
s <- 0.5
for(i in 2:10){
  fAA[i] <- s*(fAA[i-1] + fAB[i-1]/4) + (1-s)*p[i-1]^2
  fAB[i] <- s*fAB[i-1]/2 + (1-s)*2*p[i-1]*(1-p[i-1])
  fBB[i] <- s*(fBB[i-1] + fAB[i-1]/4) + (1-s)*(1-p[i-1])^2
  p[i] <- fAA[i] + fAB[i]/2
}
```

```{r echo=FALSE, fig.cap="Figure 4.3 Expectation for genotype frequencies for a 2-allele locus where $p=0.25$ and the selfing rate $s=0.5$.", message=FALSE, warning=FALSE}
library(ggplot2)
df <- data.frame( F=c(fAA,fAB,fBB), T=rep( 1:10, times=3), Genotype=rep(c("AA","AB","BB"), each=length(fAA)))
ggplot(df,aes(x=T,y=F,color=Genotype)) + geom_line() + geom_point() + xlab("Generation (t)") + ylab("Genotype Frequency") + ylim(0,1)
```


The resulting frequencies look to come to equilibrium at a reasonable speed.  The frequency of heterozygotes decreases from what would be expected under HWE yet does not go to zero.  The fraction of offspring that are the result of outcross matings ($1-s$) replenish heterozygotes preventing their entire loss.  After a few generations in this simple model, we see that the genotype frequencies can come into equilibrium.  

It would be possible to ‘cheat' a little on those estimations as $fBB[i] = 1-(fAA[i]+fAB[i])$ in the code above but I think that is one way to cover up potentially problematic bugs in your code.  All code has bugs—do not delude yourself into thinking otherwise.  One way we can have some confidence in the code we write that we know the frequencies of the three genotypes should sum to unity.

```{r}
fAA + fAB + fBB
```

Another way is to give the code parameters where we know what the outcome should be.  For example, if $s=0$, we should see any distribution of genotype frequencies tend towards Hardy-Weinberg Equilibrium.  In fact, it should tend very quickly towards HWE, right? 

In a fashion similar to selfing, we can use real data as well to examine genotype frequency change.  The gstudio library has a function `mixed_mating()` that allows you to specify the selfing rate s. I'll let you play with that one on your own time.

## Mixed Mating Genotype Frequency Equilibriums

In mixed mating systems, there is an intermediate equilibrium frequency for each genotype frequency created by the opposing forces of HWE in the ($1-s$) fraction of the offspring that tend towards p2, 2pq, and q2 and the tendency of pure selfing ($s$) to remove half the heterozygotes each generation.  

There are two equilibriums states that are possible:  

1. When we have fixed allele frequencies (e.g., $p=1.0$).  OK, this is kind of a boring example, but it is an equilibrium (as long as there is no mutation).  
2. The one we are interested in where $Q_t = Q_{t+1}$.  We can solve for this one by setting them equal in the expectation equation and solving for $\hat{Q}$. The part after the fourth line is just making it more simplified.
 
\[
\begin{aligned}
\hat{Q} &= s\frac{\hat{Q}}{2} + (1-s)2pq \\
 \hat{Q}-s\frac{\hat{Q}}{2} &= (1-s)2pq \\
\hat{Q}\left( 1 - \frac{s}{2} \right) &= (1-s)2pq \\
\hat{Q} &= \frac{(1-s)2pq}{1-\frac{s}{2}} \\
\hat{Q} &= \frac{2}{2}\frac{(1-s)2pq}{1-\frac{s}{2}} \\
\hat{Q} &= \frac{(1-s)4pq}{2-s}
\end{aligned}
\]

If this is a calculation that is necessary to use several times, it is easy to wrap it into a function as:

```{r}
equilbrium.Q <- function(p,s){
  q <- 1-p
  return(((1 - s) * 4 * p * q)/(2 - s))
}
```

and then you will be able to use it as necessary.

```{r}
equilbrium.Q(0.5,1)
equilbrium.Q(0.5,0)
equilbrium.Q(0.25,0.25)
```
The same approach can be used to estimate expected genotype frequencies for the homozygotes, setting for example $P_{t+1} = P_t$ 

\[
\begin{aligned}
\hat{P} & =  s(\hat{P}+\frac{Q}{4}) + (1-s)p^2 \\
\hat{P} & =  s\hat{P} + \frac{1}{4}sQ + (1-s)p^2\\
\hat{P} - s\hat{P} & =  \frac{1}{4}sQ + (1-s)p^2 \\
\hat{P}(1-s) & =  \frac{1}{4}sQ + (1-s)p^2 
\end{aligned}
\]

then solving for $\hat{P}$ (or $\hat{R}$ as necessary) gives the equilibrium genotype frequency

\[
\begin{aligned}
\hat{P} & =  \frac{s\frac{Q}{4}}{(1-s)} + p^2\\
\hat{P} & =  \frac{\frac{1}{4}s\frac{(1-s)4pq}{2-s}}{(1-s)} + p^2\\
\hat{P} & =  \frac{spq}{2-s} + p^2
\end{aligned}
\]

Since the genotype frequencies tend towards an equilibrium, then the inbreeding parameter, $F$, will also tend towards its corresponding equilibrium, $\hat{f}$.  The value of this equilibrium can be found by substituting the expected heterozygote frequency  

\[
\hat{Q}=\frac{(1-s)4pq}{2-s}
\]

into the inbreeding equation and putting it in place of $H_O$.

\[
F = 1 - \frac{H_O}{H_E}
\]

and simplifying in a few steps we get

\[
\hat{F} = \frac{s}{2-s}
\]

The rage at which $F$ goes from 0 to $\hat{F}$ can be estimated much like the derivation provided for changes in allele frequencies due to mutation. 

It is 

\[
F_t = \frac{s}{2-s}\left[ 1-\frac{s^t}{2} \right] + \left[\frac{s}{2}\right]^tF_0
\]

depending upon only the selfing rate, the starting inbreeding level, and the current generation.

Here is a little gadget to play with that allows you to manipulate $F_0$, $s$ and the number of generations ($T$).

```{r echo=FALSE}
knitr::include_app("http://popgen.bio.vcu.edu/shiny/apg/selfing_F/", height="850")
```


## Estimating Selfing Rates

As with most things in population genetics, these expectations provide nice descriptions of what we expect to see in the wild, but at the end of the day we are stuck with a bunch of raw genotypes and the need to find an estimation of $s$. In fact, it is usually the value of $s$ that we are most interested in seeking, not the value of $F$.   It is possible though, to rearrange the equilibrium expectation of $\hat{F}$, solving for s and thereby providing a first approximation for population-level selfing rates (or at least the equivalent selfing rate given a bunch of other expectations). 

\[
\hat{s} = \frac{2F}{1+F}
\]

In some cases, this approximation would make sense—cases such as a study of plants where selfing is a potential outcome of mating (e.g., Schemske & Lande 1985)—but may be somewhat meaningless (in a direct sense) to species whose mating system does not allow selfing (e.g., most non-plant species).  That said, the estimate $\hat{s}$ is an idealized parameter and because it is based solely upon inbreeding, $F$, it is an integrative parameter incorporating mating patterns not just during a single round of mating but as an accumulation across many mating events as well as other forms of non-random mating such as consanguinity.

```{r echo=FALSE, fig.cap="Expected equilibrium for inbreeding parameter, F, across potential values for the selfing rate, s."}
df <- data.frame( s=seq(0,1,by=0.02))
df$F <- df$s/(2-df$s)
ggplot( df, aes(x=s,y=F) ) + geom_line() + geom_point()
```









## F-Statistics and Thier Ilk

The most commonly used parameter for in population genetics are derived from Wright's $F$-Statistics.  We have already encountered one of them, the inbreeding parameter F, which we calculated using the `genetic_diversity()` function using `mode="Fis"`.  This parameter compares the level of observed heterozygosity to that expected under HWE as:

\[
F_{IS} = 1 - \frac{H_O}{H_E}
\]

If the locale in question is producing heterozygotes at a rate consistent with HWE then there is no 'inbreeding' (as we defined it previously).  This being said, the expected frequency of heterozygotes can be estimated at several different demographic levels if you have data that is subdivided.  Assuming you have individuals, sampled from K different locales, you can estimate heterozygosity at the following levels:  

- Individual heterozygosity ($H_I$):  This is what we've been calling HO, observed heterozygosity and is estimated as the fraction of heterozygotes in your sample for a particular locale, $H_I = \frac{N_{ij}}{N}$.  This value can be interpreted as the “average heterozygosity of all genes in an individual" or as “the probability of observing a heterozygote at a particular locus."  
- Subpopulation heterozygosity ($H_S$):  This is the rate of heterozygosity expected at a particular sampling sub-population (or what I refer to in this text as a locale).  This is estimated as the average in expected heterozygosity ($H_E$) across all $K$ sampling locales; $H_S = \frac{1}{K}\sum_{i=1}^K 2p_iq_i$.  It assumes that each of your sampling locales is in HWE, each conforming to the host of assumptions necessary to satisfy that condition.  
- Total heterozygosity ($H_T$):  This is the total heterozygosity across all the data.  This is the expected heterozygosity if all the data were merged and mating as a single panmictic population.  This parameter is estimated as $H_T = 2\bar{p}\bar{q}$, where the frequencies for each allele are determined as the average across all sampling locales.

If the underlying mating patterns among subdivided populations restrict *gene flow*, then these estimates of heterozygosity will change. At one extreme, if all populations are mixing freely and it is essentially a single panmictic population then heterozygosity at the sub-population and total population levels will be equal, $H_T=H_S$, independent of the amount of inbreeding (or consanguineous mating that is actually occurring).  At the other extreme, if all locales are genetically isolated from each other, then each will be diverging its own evolutionary trajectory both sub-population and total estimates of heterozygosity will diverge.  In fact, it is exactly these relationships between estimates of heterozygosity that Sewell Wright used to derive the oft-misused $F$-Statistics.  

To date, we've already used one of these parameters, when examining inbreeding.  Our $F$-statistic is the first demographic level.  Using this new terminology for heterozygosity, the inbreeding statistic is defined as: 

\begin{aligned}
F_{IS} &= \frac{H_S - H_I}{H_S} \\
& = 1 - \frac{H_I}{H_S}
\end{aligned}

where the subscripts on the parameters reveal the sampling level being used.  In this case, the subscripts on $F_{IS}$ stand for “inbreeding of _I_ndividuals relative to the _S_ubpopulation they are sampled."  The values of this parameter are positive when we see less heterozygotes than expected, and can be negative when we see more heterozygotes than expected under HWE.  This parameter makes particular sense in light of unknown subdivision in populations, the Wahlund Effect discussed earlier.  

At the next level, we can examine inbreeding of the Subpopulation relative to the Total data set, $F_{ST}$.  This is defined as:

\begin{aligned}
F_{ST} &= \frac{H_T - H_S}{H_T} \\
&= 1 - \frac{H_S}{H_T}
\end{aligned}

This parameter has been so misused in the literature, it is almost a caricature of itself.  As we see from the formula, it is the reduction in heterozygosity of the subpopulation relative to the entire data set.  This parameter can be either positive or negative.  Wright's original formulation of the parameter $F_{ST}$ was as:

\begin{aligned}
F_{ST} & = \frac{\sum_{i=1}^\ell \sigma_{q_{S(i)}}^2}{\sum_{i=1}^\ell \left[ q_{T(i)}\left( 1 - q_{T(i)}\right) \right]} \\
& = 1 - \frac{y_{ST}}{y_T}
\end{aligned}

Where $\sum_{i=1}^\ell \sigma_{q_{S(i)}}^2$ is the variance in allele frequencies across subpopulations (the $S(i)$ subscript) using all $\ell$ alleles at the locus, and $q_{T(i)}$ is the average allele frequency across all subpopulations.  The parameters $y_{ST}$ and $y_T$ are equivalent to $H_S$ (average expected heterozygosity across subpopulations) and $H_T$ (expected heterozygosity of average allele frequencies) respectively. 

Lets take a simple example and work though this for clarity as the estimators $H_S$ and $H_T$ can be a bit confusing at times.  Consider the case where we have three populations assayed for a single bi-allelic locus.  Allele frequencies at each of the populations are:

```{r}
p <- c(0.2, 0.3, 0.4)
q <- 1-p
```

which give an expected heterozygosity of:

```{r}
hs <- 2*p*q
hs
```

Whose average is:

```{r}
mean(hs)
```

For $H_T$, we estimate the average of the allele frequencies ($\bar{p}$ and $\bar{q}$) and then the expectation for heterozygosity ($2\bar{p}\bar{q}$) as:

```{r}
pbar <- mean(p)
qbar <- mean(q)
ht <- 2*pbar*qbar
ht
```

From these values, we can estimate $F_{ST}$ as:

\begin{aligned}
F_{ST}  & = 1 - \frac{H_S}{H_T} \\
&= 1 - \frac{0.4067}{0.42} \\
& \approx 0.317
\end{aligned}

Values of $F_{ST}$ that are close to zero indicate low levels of differentiation, whereas those close to unity represent complete differentiation (with very important caveats that follow).

### Issues with Fixation Indices

One could interpret the original configuration of $F_{ST}$ as being a ratio of variances.  The numerator is the variance in allele frequencies across sampled locations and the denominator is essentially the variance of binomial (or multinomial if $\ell > 2$).

The largest issues with this parameter is that it is NOT a measure of genetic differentiation in the sense that it tells us how different populations are (e.g., how we would use this term in the common vernacular).  In fact, Sewell Wright (1984) specifically states that

$F_{ST}$ can be interpreted as a measure of the amount of differentiation among subpopulations, relative to the limiting amount under complete fixation...

This can be seen in the following examples and the values we get for the parameter $F_{ST}$ in each.  

*Scenario 1:* Two populations, `A` and `B`, each fixed for a different allele. In this case, the heterozygosity at population `A` would be $2p_Aq_A = 2*0*1 = 0$, likewise for population `B` at $2p_Bq_B = 2*1*0 = 0$, and the estimate of subpopulation heterozygosity is $H_S = \frac{0+0}{2} = 0$.  Total heterozygosity, $H_T$, is defined using allele frequencies averaged across populations and would be $H_T = 2\bar{p}\bar{q} = 2*0.5*0.5 = 0.5$ making $F_{ST} = 1 - \frac{0}{0.5} = 1.0$.  These two populations are diverged completely from each other and this makes sense.  Subpopulation heterozygosity, $H_S$, is *always* zero when any number of populations are fixed for a single allele.

*Scenario 2:* Two populations with two alleles each, though not the same alleles.  In the most simple case lest assume population `A` is in HWE with alleles `A` and `B` occurring at equal frequencies and the other population has alleles `C` and `D` also at equal frequencies.  In this case, heterozygosity at each population would be $H_{S,A} = H_{S,B} = 0.5$ and $H_S = 0.5$ as it is the average of the expected population-level heterozygosity.  The total expected heterozygosity is the heterozygosity of allele frequencies averaged across populations, which in this simple example we have $\bar{p}_A = \bar{p}_B = \bar{p}_C = \bar{p}_D$  and $H_T = 1 - \sum_{i=1}^\ell p_i^2 = 0.75$^[When we have more than 2 alleles at a locus, it is often easier to estimate the part that is not homozygote rather than adding up for example $2pq + 2pr + 2ps + 2qr + 2qs + 2rs$ to estimate heterozygotes.]  This makes $F_{ST} = \frac{H_T - H_S}{H_T} = \frac{0.75 - 0.25}{0.75} = 0.33$.  Intuitively, this does not make much sense, why would it be a third if *both* populations are in HWE, just for different alleles?

*Scenario 3:* Three populations, the first of which is fixed for allele `A` and the rest that are fixed for allele `B`.  In this scenario, $H_S = \frac{1}{3}\left[ 2p_1q_1 + 2p_2q_2 + 2p_3q_3 \right] = 0$ but $H_T$, being defined as the expected heterozygosity of averaged allele frequencies, $\bar{p} = \frac{1+0+0}{3} = 0.33$ and $\bar{q} = \frac{0+1+1}{3} = 0.66$ would be $H_T = 2\bar{p}\bar{q} = 2*0.33*0.66 = 0.4356$ and $F_{ST} = \frac{0.4356 - 0}{0.4356} = 1$.  Again, when populations are fixed for different alleles, $F_{ST} = 1.0$.  However, in this case, two of our populations are entirely identical!  How is it that the two populations with identical allele frequencies (and whose own $F_{ST} = 0$ by the way) can cause $F_{ST}$ to go to unity?  In fact, we could have 100 populations fixed for one allele and 1 population fixed for the other and still have $F_{ST} = 1.0$!

This is because, as Wright (1984, pg 82) pointed out:

>> The fixation index is thus not a measure of degree of differentiation in the sense implied by the extreme case by absence of any common allele.  It measures differentiation within the total array in the sense of the extent to which the process of fixation has gone towards completion.

This is not how it is used in the literature, where it is often used to describe the differences among populations in an absolute sense.  This is why these are called fixation indices (the $F$ is for fixation).

For completeness, we can also estimate the inbreeding of an individual relative to the total population, 

\[
F_{IT} = \frac{H_T - H_I}{H_T}
\]

though it is not often used because individuals are inbred relative to the populations within which they are found, not within which the entire dataset is composed.  Moreover, the three parameters have the following relationship, 

\[
(1-F_{IS})(1-F_{ST}) = (1-F_{IT})
\]

which means that once $F_{IS}$ and $F_{ST}$ are estimated, $F_{IT}$ is completely defined.  

Before we jump into some data, we need to address one more issue that we are confronted with.

*Scenario 4:* Estimation of the population-level heterozygosity is not done without error.  In fact, we are estimating these parameters for each of the populations and every time we need to determine estimates of allele frequencies.  As such, if we are going to take this into consideration, we need to correct estimates of heterozygosity accordingly.

Here is an example of the differences we will see if we do not account for these problems (as well as the issue of samples sizes and sampling locations discussed in \@ref(samples-from-several-locales)).  In the arapat data set, I'm going to use the two of the mainland populations and estimate $F_{ST}$ from them for a single locus as an example to demonstrate this last issue and show the magnitude of the bias that may be introduced by not considering that each of the stratum have estimated heterozygosity with a bit of error.

```{r message=FALSE, warning=FALSE}
require(gstudio)
data(arapat)
df <- arapat[ arapat$Population %in% c("101","102"), c(3,13)]
df <- droplevels( df )
```

Here is what that looks like (the `droplevels()` bit is to remove the non-observed populations from the stratum column in the derived `data.frame`).

```{r}
df
```

If you look at the alleles present by locus, you can see quite that the allele frequencies (above) are not that close to each other—in fact, population `101` has the `04` allele that is not present in population 102.  Numerically, they are:

```{r}
frequencies(df, stratum = "Population")
```

If we estimate heterozygosity directly for each population we see that the individual, population-level, heterozygosity, is estimated as:

```{r}
x <- c(genetic_diversity(df[df$Population=="101",],mode="He")$He, genetic_diversity(df[df$Population=="102",],mode="He")$He)
x
```

which results in an estimate of $H_S$:

```{r}
hs <- mean(x)
hs
```

Similarly, the parameter $H_T$ is:

```{r}
ht <- genetic_diversity(df,mode="He")$He
ht
```

We can estimate $F_{ST}$ as:

```{r}
Fst_biased <- 1 - hs/ht
Fst_biased
```

If we do take into consideration the error associated with estimating these parameters, we find a much smaller value:

```{r}
Fst(df)
```

Notice here that $H_S$ is estimated from averaging (the first way) 10% lower than done when considering sampling allocations.  The bias associated with $H_T$ is much smaller but exists all the same.  Overall, the problem here is an overestimation of $F_{ST}$ by a factor of almost 3!  These results are exaggerated a bit because of the small size—it would be foolish to estimate $F_{ST}$ from only N=17 individuals from two populations.  However, it does show the importance of considering sampling allocations.  As you sample more individuals, these estimates of heterozygosity will converge.

### Additional $X_{ST}$-like Parameters

The use (and perhaps misuse) of [~] has supported the development of almost a cottage industry in other parameters, each trying to fit into a specific perceived problem in the original parameter.  Here are some other extensions of this basic parameter that you may come across:  

- $R_{ST}$ for Microsatellite loci.  This uses the ladder genetic distance metric discussed previously.  
- $N_{ST}$ for Nucleotides variation.  
- $G_{ST}$ for population subdivision (and in some cases mutation).  
- $G_{ST}^\prime$ for loci with high allelic diversity (along with its nemesis $D_{est}$).

Each of these parameters attempts to solve an additional problem that people have posed for $F_{ST}$.  The magnitude of bias associated with each may be differential, depending upon the extent to which your data are violating underlying assumptions.  For example, at highly diverse loci, the expectation for [~] is limited in that it cannot reach its theoretical maximum.  As such, Hedrick (ref) has derived the [~] parameter that corrects for this.  In general, the degree to which [~] and [~] diverge depend upon both the diversity and the evenness of allele frequencies in your populations.  This begs the question, “Is there a cutoff when I should not longer use [~] and prefer [~] instead?"  I think Hedrick would suggest to always use it the secondary one, just in case, though it may be in your best interest to examine the differences in the parameters in your own data first.

Here is an example of how these parameters may give alternative estimates.  I'll use the MP20 locus as it is a microsatellite locus of high diversity and compare the [~], [~], and [~] estimates.

```{r}
df <- arapat[, c(3,14)]
genetic_structure(df,stratum="Population",mode="Gst")
genetic_structure(df,stratum="Population",mode="Gst_prime")
genetic_structure(df,stratum="Population",mode="Dest")
```

Is the diversity at this locus influencing structure estimation?  Yes, you can clearly see that [~] alone produces a much smaller value than the other parameters.  Which of the other ones are more accurate?  That is an interpretive question you have to answer knowing your study system.

## Statistical Structure

Thus far, we've examined parameters that describe genetic structure, in relation to fixation.  These paremeters are all based upon underlying population genetic assumptions.  However, that need not be the case.  In 1984, Wier & Cockerham derived a parameter [~], which was an estimator for [~] but based upon an analysis of variance approach rather than expectations relying upon heterozygosity. This statistic is essentially a variance ratio, derived from a random-effects analysis of variance model, just like we would use in normal parametric statistics.  Later, Excoffier et al. (1992) expanded upon this approach to provide a multilocus estimate of this parameter, which they called [~] using an analysis they termed AMOVA (for Analysis of MOlecular VAriance).  In 2004, Dyer et al. showed how both of these approaches are just special cases of a more general family of Q-mode linear regression models, amenable to broad ranges of sampling designs and configurations.  In what follows, I'm going to focus on the AMOVA configuration, mostly for completeness in relation to the individual AMVOA distance described previously (reproduced on the right).  The geometry of this encoding provides an easy heuristic for quantifying genetic distances between pairs of individuals.

Taken as a whole, the distance among all N individuals can be represented as a pairwise genetic distance matrix, [~].  This matrix has the form:

[~]  TODO

which is symmetric ([~]) and has zero squared distance down the diagonal ([~]).  This can be evaluated as an Analysis of Variance by decomposing the squared distance values into the Total Sums of Squared Distances

[~], 

the Sums of Squared Distances Within strata

[~]

and the Sums of Squared Distances Among populations.

[~]

The notation is a bit odd here, but it is essentially all the squared distances between individuals found in different populations.

You can visualize these parameters in matrix form as depicted below. The pairwise distance matrix has individuals in it sorted in order of appearance within populations.  As such, [~] is the sum of all squared distances and is decomposed to the additive components of [~] (summing distances within populations), and [~] (summing values representing among stratum distances). For each of these parameters is standardized by the number of entries in that particular group.

These sums of squares are easily put into a traditional AMOVA table.  From here, it is identical to a normal ANOVA analysis.  We have degrees of freedom, mean squares, and variance components.  The AMOVA itself, due to the way we sample the individuals and populations is a random-effects model.  Our sampling typically consists of us going out and sampling a portion of the potential populations that exist rather than sampling all specified populations.  As a statistical consequence, this means that the variance within (the error term) and among (the treatment variance) have to be corrected because we are taking only a sample from all potential populations.  For a 1-level analysis, we can perform this in R by first setting up the data as a distance matrix and a vector of population assignments (it appears that the values need to be either numeric or as a factor for populations, though at the time of this writing, I could not get a factor representation to work properly).

```{r}
D <- genetic_distance(arapat, stratum="Population", mode="AMOVA")
D <- as.dist( D )
pop <- as.numeric( arapat$Population )
```

and then using the `amova()` function from the pegas library (there are many different implementations of this kind of analysis, decompose the variance into and fill out the AMOVA table as:

```{r}
require(pegas)
fit <- amova( D ~ pop, nperm=1000 )
fit
```

This gives us the standard anova table and an estimate of the probability associated with the variance component representing among-population variance, $\sigma_A^2$.  
The estimated variance components of this model, we can estimate a structure statistic, $\Phi_{ST}$, which for a 1-level analysis is

\[
\Phi_{ST} = \frac{\sigma_A^2}{\sigma_A^2+\sigma_W^2}
\]

and from the output of the amova() function can be estimated as (don't know why this isn't done automagically)

```{r}
PhiST <- 1 - fit$varcoef/(fit$varcoef+fit$varcomp[2,1])
PhiST
```

Which means that roughly `r print(PhiST*100,digits=3)`% of the genetic variation observed in these data can be attributed to individuals being assigned to different populations.

## Final Thoughts on Structure

The estimation of genetic structure is a fundamental endeavor in population genetics that at times can be given a bit more weight than it may warrant.  These parameters are simply estimates of a magnitude of structure in relation to either the degree to which populations have gone to fixation or as a statistical decomposition of raw variation.  The important component here is that there are a lot of ways that a set of population histories may result in the same amount of genetic variation.  The important point here is that simply looking at the magnitude of variation among strata does not allow us to differentiate among alternative demographic histories.  





